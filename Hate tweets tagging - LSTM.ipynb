{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6FZoxF2vVGEy"
   },
   "source": [
    "# Twitter sentiment analysis V1 - feature engineering\n",
    "- Features created: None\n",
    "- Model : LSTM\n",
    "- External preprocessing : GloVe word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "C1BuJ-CZWyg1"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\n",
    "from keras.layers import LSTM,Dense,Dropout,Embedding,Bidirectional, Input\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train = pd.read_csv(\"train_E6oV3lV.csv\")\n",
    "test = pd.read_csv(\"test_tweets_anuFYb8.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VJ8ic1-tXYXB"
   },
   "outputs": [],
   "source": [
    "# This cell has a function for text processing\n",
    "# But I ended up not using it in the final result\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from wordcloud import STOPWORDS\n",
    "\n",
    "\n",
    "class FeatureCreation:\n",
    "\n",
    "\n",
    "  \"\"\"Takes pandas dataframe and text column name and returns a pandas dataframe \n",
    "  with additional word based columns\n",
    "  ...\n",
    "\n",
    "  Attributes\n",
    "  -----------\n",
    "  dataset: pandas dataframe input\n",
    "  textcol: feature name string\n",
    "\n",
    "  Methods\n",
    "  -----------\n",
    "  get_features()\n",
    "    returns dataframe with 9 word based features\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "  def __init__(self, dataset: pd.DataFrame, textcol: str):\n",
    "      self.dataset = dataset\n",
    "      self.textcol = textcol\n",
    "\n",
    "  def get_features(self):\n",
    "      df_var = self.dataset\n",
    "      # word count\n",
    "      text_col = self.textcol\n",
    "      df_var['word_count'] = df_var[text_col].apply(lambda x: len(str(x).split()))\n",
    "      # get unique words\n",
    "      df_var['unique_word_count'] = df_var[text_col].apply(\n",
    "          lambda x: len(set(str(x).split())))\n",
    "      # get stop words\n",
    "      df_var['stop_word_count'] = df_var[text_col].apply(\n",
    "          lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS\n",
    "            ]))\n",
    "      df_var['url_count'] = df_var[text_col].apply(\n",
    "          lambda x: len([w for w in str(x).lower().split() if \"http\" in w or \"https\" in w]))\n",
    "      df_var['mean_word_length'] = df_var[text_col].apply(\n",
    "          lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "      df_var['char_count'] = df_var[text_col].apply(lambda x: len(str(x)))\n",
    "      df_var['punctuation_count'] = df_var[text_col].apply(\n",
    "          lambda x: len([w for w in str(x) if w in string.punctuation]))\n",
    "      df_var['hashtag_count'] = df_var[text_col].apply(\n",
    "          lambda x: len([w for w in str(x) if w == \"#\"]))\n",
    "      df_var['mention_count'] = df_var[text_col].apply(\n",
    "          lambda x: len([w for w in str(x) if w == \"@\"]))\n",
    "\n",
    "      return df_var\n",
    "\n",
    "  def remove_specials(self):\n",
    "    #pattern = re.compile('[\\W_]+')\n",
    "    dfcleantext = self.dataset\n",
    "    text_col = self.textcol\n",
    "    dfcleantext[text_col] = dfcleantext[text_col].apply(\n",
    "        lambda x: re.sub(r'([^\\s\\w]|_)+', '', x))\n",
    "    return dfcleantext\n",
    "      \n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "def f1(y_true, y_pred):\n",
    "    y_pred = K.round(y_pred)\n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return K.mean(f1)\n",
    "\n",
    "def f1_loss(y_true, y_pred):\n",
    "    \n",
    "    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "    tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "    p = tp / (tp + fp + K.epsilon())\n",
    "    r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "    f1 = 2*p*r / (p+r+K.epsilon())\n",
    "    f1 = tf.where(tf.math.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "    return 1 - K.mean(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "soWrYI_EZhn2",
    "outputId": "98f40278-54e8-4522-edbc-2eace544df83"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4.555556</td>\n",
       "      <td>102</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5.315789</td>\n",
       "      <td>122</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.928571</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label  ... hashtag_count  mention_count\n",
       "0   1      0  ...             1              1\n",
       "1   2      0  ...             3              2\n",
       "2   3      0  ...             0              0\n",
       "3   4      0  ...             1              0\n",
       "4   5      0  ...             1              0\n",
       "\n",
       "[5 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_obj = FeatureCreation(train,'tweet')\n",
    "train_features = train_obj.get_features()\n",
    "#train_obj = FeatureCreation(train_features,'tweet')\n",
    "#train_features = train_obj.remove_specials()\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "Y6cBI_ZIShPb",
    "outputId": "522f5a55-4954-42ba-9b8d-7c215cc35bf6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>word_count</th>\n",
       "      <th>unique_word_count</th>\n",
       "      <th>stop_word_count</th>\n",
       "      <th>url_count</th>\n",
       "      <th>mean_word_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>hashtag_count</th>\n",
       "      <th>mention_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31963</td>\n",
       "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.777778</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31964</td>\n",
       "      <td>@user #white #supremacists want everyone to s...</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>101</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31965</td>\n",
       "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6.333333</td>\n",
       "      <td>71</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31966</td>\n",
       "      <td>is the hp and the cursed child book up for res...</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>5.409091</td>\n",
       "      <td>142</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31967</td>\n",
       "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5.066667</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  ... mention_count\n",
       "0  31963  ...             0\n",
       "1  31964  ...             1\n",
       "2  31965  ...             0\n",
       "3  31966  ...             0\n",
       "4  31967  ...             0\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_obj = FeatureCreation(test,'tweet')\n",
    "test_features = test_obj.get_features()\n",
    "#test_obj = FeatureCreation(test_features,'tweet')\n",
    "#test_features = test_obj.remove_specials()\n",
    "test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZNoK8K-uOdTq"
   },
   "outputs": [],
   "source": [
    "x = train_features['tweet']\n",
    "y = train_features['label']\n",
    "token  = Tokenizer()\n",
    "token.fit_on_texts(x)\n",
    "seq = token.texts_to_sequences(x)\n",
    "pad_seq = pad_sequences(seq, maxlen=300)\n",
    "vocab_size = len(token.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SOm4GuRrTpie",
    "outputId": "bb9310a0-2176-46b3-e6ae-40bdaedcc2ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45889/45889 [00:00<00:00, 575601.23it/s]\n"
     ]
    }
   ],
   "source": [
    "embedding_vector = np.load(\"glove.840B.300d.pkl\", allow_pickle=True)\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size,300))\n",
    "for word,i in tqdm(token.word_index.items()):\n",
    "  embedding_value = embedding_vector.get(word)\n",
    "  if embedding_value is not None:\n",
    "    embedding_matrix[i] = embedding_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VjTumtfXBq_p"
   },
   "outputs": [],
   "source": [
    "# Make our meta features usable for deep learning along with the text data in LSTM\n",
    "meta_features = ['word_count', 'unique_word_count',\n",
    "       'stop_word_count', 'url_count', 'mean_word_length', 'char_count',\n",
    "       'punctuation_count', 'hashtag_count', 'mention_count']\n",
    "train_meta = train_features[meta_features].values\n",
    "test_meta = test_features[meta_features].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ReXKcHGWEzKP"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "train_meta = normalize(train_meta, norm='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3UIG9FHdEd2p"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tbmJrTtfcgIP"
   },
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=6)]\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size,300,weights = [embedding_matrix],input_length=300,trainable = False))\n",
    "model.add(Dense(32,activation = 'relu'))\n",
    "model.add(Bidirectional(LSTM(32)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(16,activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics = [f1,'accuracy'])\n",
    "history = model.fit(pad_seq,y,epochs = 16,batch_size=64,validation_split=0.2, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wTSS5buCaD9",
    "outputId": "34fcd22c-8d97-411f-96f0-ee82132e09c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 300)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 9)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 300, 300)     13767000    input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 16)           160         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  (None, 64)           93440       embedding_12[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 16)           272         dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 80)           0           lstm_12[0][0]                    \n",
      "                                                                 dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 16)           1296        concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 1)            17          dense_50[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 13,862,185\n",
      "Trainable params: 95,185\n",
      "Non-trainable params: 13,767,000\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create functional deep learning layers instead of Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l1\n",
    "input_1 = Input(shape=(300,))\n",
    "input_2 = Input(shape=(9,))\n",
    "\n",
    "embedding_layer = Embedding(vocab_size, 300, weights=[embedding_matrix], trainable=False)(input_1)\n",
    "LSTM_Layer_1 = LSTM(64, dropout=0.4)(embedding_layer)\n",
    "\n",
    "dense_layer_1 = Dense(16, activation='relu', bias_regularizer=l1(0.005))(input_2)\n",
    "dense_layer_2 = Dense(16, activation='relu', bias_regularizer=l1(0.005))(dense_layer_1)\n",
    "\n",
    "concat_layer = Concatenate()([LSTM_Layer_1, dense_layer_2])\n",
    "dense_layer_3 = Dense(16, activation='relu')(concat_layer)\n",
    "output = Dense(1, activation='sigmoid')(dense_layer_3)\n",
    "model = Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy',f1])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uApa296bEBzU",
    "outputId": "80cd638a-0c7a-470b-992b-9939201b9dec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 7s 104ms/step - loss: 0.3200 - accuracy: 0.9312 - f1: 0.0102 - val_loss: 0.1683 - val_accuracy: 0.9388 - val_f1: 0.3143\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.1674 - accuracy: 0.9384 - f1: 0.3995 - val_loss: 0.1437 - val_accuracy: 0.9427 - val_f1: 0.4972\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.1447 - accuracy: 0.9464 - f1: 0.5324 - val_loss: 0.1402 - val_accuracy: 0.9437 - val_f1: 0.5490\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.1378 - accuracy: 0.9487 - f1: 0.5461 - val_loss: 0.1284 - val_accuracy: 0.9492 - val_f1: 0.5587\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.1334 - accuracy: 0.9512 - f1: 0.5985 - val_loss: 0.1286 - val_accuracy: 0.9532 - val_f1: 0.5602\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.1211 - accuracy: 0.9564 - f1: 0.6209 - val_loss: 0.1207 - val_accuracy: 0.9540 - val_f1: 0.5765\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.1157 - accuracy: 0.9585 - f1: 0.6409 - val_loss: 0.1173 - val_accuracy: 0.9545 - val_f1: 0.6242\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.1100 - accuracy: 0.9600 - f1: 0.6634 - val_loss: 0.1170 - val_accuracy: 0.9556 - val_f1: 0.6277\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.1077 - accuracy: 0.9617 - f1: 0.6965 - val_loss: 0.1168 - val_accuracy: 0.9557 - val_f1: 0.6219\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0988 - accuracy: 0.9648 - f1: 0.7179 - val_loss: 0.1154 - val_accuracy: 0.9573 - val_f1: 0.6283\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0950 - accuracy: 0.9660 - f1: 0.7218 - val_loss: 0.1110 - val_accuracy: 0.9600 - val_f1: 0.6867\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 5s 94ms/step - loss: 0.0933 - accuracy: 0.9661 - f1: 0.7322 - val_loss: 0.1129 - val_accuracy: 0.9587 - val_f1: 0.6583\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0859 - accuracy: 0.9696 - f1: 0.7543 - val_loss: 0.1175 - val_accuracy: 0.9589 - val_f1: 0.6148\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0767 - accuracy: 0.9725 - f1: 0.7679 - val_loss: 0.1087 - val_accuracy: 0.9611 - val_f1: 0.6774\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0791 - accuracy: 0.9717 - f1: 0.7674 - val_loss: 0.1164 - val_accuracy: 0.9595 - val_f1: 0.6514\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0782 - accuracy: 0.9728 - f1: 0.7961 - val_loss: 0.1181 - val_accuracy: 0.9606 - val_f1: 0.6482\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0693 - accuracy: 0.9755 - f1: 0.8038 - val_loss: 0.1168 - val_accuracy: 0.9606 - val_f1: 0.6628\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0633 - accuracy: 0.9770 - f1: 0.8186 - val_loss: 0.1113 - val_accuracy: 0.9625 - val_f1: 0.6991\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 5s 96ms/step - loss: 0.0606 - accuracy: 0.9778 - f1: 0.8314 - val_loss: 0.1179 - val_accuracy: 0.9598 - val_f1: 0.6827\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 5s 95ms/step - loss: 0.0562 - accuracy: 0.9798 - f1: 0.8499 - val_loss: 0.1160 - val_accuracy: 0.9589 - val_f1: 0.6959\n"
     ]
    }
   ],
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=6)]\n",
    "history = model.fit(x=[pad_seq, train_meta], y=y, batch_size=512, epochs=30, verbose=1, validation_split=0.2,callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXh71VqlVtQW",
    "outputId": "df40363f-e5ad-47e4-f213-c8217fff8aef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16033\n",
       "1     1164\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = pd.read_csv('sample_submission_gfvA5FD.csv')\n",
    "x_test = test['tweet']\n",
    "x_test = token.texts_to_sequences(x_test)\n",
    "testing_seq = pad_sequences(x_test, maxlen=300)\n",
    "test_meta = normalize(test_meta, norm='max', axis=0)\n",
    "predict = np.round(model.predict([testing_seq,test_meta])).astype('int')\n",
    "testing['label'] = predict\n",
    "testing.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "O8TuDForXCZQ"
   },
   "outputs": [],
   "source": [
    "testing.to_csv(\"submission_out_v5.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-dIbuiWZGeX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "TwitterSentimentAnalysis",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
